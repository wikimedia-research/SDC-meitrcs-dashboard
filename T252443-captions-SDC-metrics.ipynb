{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17664aac",
   "metadata": {},
   "source": [
    "# Media files containing captions in English/non-English languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72c12e-7e09-4735-ba73-e90918d1ab94",
   "metadata": {},
   "source": [
    "[T252443](https://phabricator.wikimedia.org/T252443)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49dd5b2-78b5-4e94-8bee-3619efded178",
   "metadata": {},
   "source": [
    "This set of metrics is a comparison of media files containing structured fields in English and non-English languages on a monthly basis. Including:\n",
    "- Monthly changes in media files with capitions en/non-en languages\n",
    "- Time to add captions to media files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa90d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using wmfdata v1.3.1, but v1.3.3 is available.\n",
      "\n",
      "To update, run `pip install --upgrade git+https://github.com/wikimedia/wmfdata-python.git@release --ignore-installed`.\n",
      "\n",
      "To see the changes, refer to https://github.com/wikimedia/wmfdata-python/blob/release/CHANGELOG.md\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import wmfdata \n",
    "from wmfdata import hive, spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff1da69-a23f-41a5-b74b-e0dfad821edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYSPARK_PYTHON=/usr/lib/anaconda-wmf/bin/python3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/30 06:15:17 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "22/03/30 06:15:18 WARN Utils: Service 'sparkDriver' could not bind on port 12000. Attempting port 12001.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'sparkDriver' could not bind on port 12001. Attempting port 12002.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'sparkDriver' could not bind on port 12002. Attempting port 12003.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'sparkDriver' could not bind on port 12003. Attempting port 12004.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'sparkDriver' could not bind on port 12004. Attempting port 12005.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'sparkDriver' could not bind on port 12005. Attempting port 12006.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/03/30 06:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/03/30 06:15:27 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13000. Attempting port 13001.\n",
      "22/03/30 06:15:27 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13001. Attempting port 13002.\n",
      "22/03/30 06:15:27 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13002. Attempting port 13003.\n",
      "22/03/30 06:15:27 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13003. Attempting port 13004.\n",
      "22/03/30 06:15:27 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13004. Attempting port 13005.\n",
      "22/03/30 06:15:27 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13005. Attempting port 13006.\n",
      "22/03/30 06:15:27 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n"
     ]
    }
   ],
   "source": [
    "spark = wmfdata.spark.get_session(app_name='pyspark regular',\n",
    "                                  type='yarn-large', # local, yarn-regular, yarn-large\n",
    "                                  )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f36144",
   "metadata": {},
   "source": [
    "## Configuring Timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe087a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmf_snapshot = '2022-02'\n",
    "start_date = '2022-02-01'\n",
    "end_date = '2022-03-01' # last creation date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d0374-4a67-456d-a509-ae5f76ff0bc4",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4054dc-579f-4f1c-8a34-8346b75f3290",
   "metadata": {},
   "source": [
    "According to [this ticket](https://phabricator.wikimedia.org/T231952#5710215), it's not straightforward to identify what articles contain captions in specific languages using the replicated MediaWiki databases. We would expect that the `wbc_entity_usage` table provides this information, but inspecting the entries there for a couple of pages reveals that it contains captions (\"labels\") that are not shown on the corresponding page on Commons.\n",
    "\n",
    "Instead, here we reused approaches that identifies a page getting a label added, changed, or deleted through edit comments and uses the `mediawiki_history` table in the Data Lake as the source of truth. A caption being added with the edit comment \"Added [de] caption\", where \"[de]\" is the language (German in this case, I've also seen English) as well as \"wbsetlabel-add:\".\n",
    "\n",
    "\n",
    "The majority of these operations are additions (about 1.6 million edits through December 2021), changes and deletions are two orders of magnitude fewer. Due to this huge difference, we ignore all changes/deletions and instead accept that an estimate of might be off by about 10,000 pages because the number of pages is much larger than that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb0e41",
   "metadata": {},
   "source": [
    "## Aggregation Tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5054c8e",
   "metadata": {},
   "source": [
    "We define a set of tables in the Data Lake for aggregation of results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa949bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_count_table = 'cchen_sd.caption_counts'\n",
    "caption_add_table = 'cchen_sd.caption_add_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859d33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_count_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    month DATE COMMENT \"the month of the aggregated caption counts\",\n",
    "    num_captions BIGINT COMMENT \"Number of files with captions\",\n",
    "    num_captions_non_en BIGINT COMMENT \"Number of files with non-English captions\",\n",
    "    num_captions_en BIGINT COMMENT \"Number of files with English captions\",\n",
    "    num_captions_both BIGINT COMMENT \"Number of files with both (sum of the latter two minus the first)\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff17041",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_time_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    month DATE COMMENT \"the month of the aggregated caption time counts\",\n",
    "    caption_language STRING COMMENT \"English or non-English captions\",\n",
    "    caption_time STRING COMMENT \"How quickly after creation do captions get added\",\n",
    "    max_caption_time BIGINT COMMENT \"max caption time within each bucket (for Superset chart)\",\n",
    "    num_captions BIGINT COMMENT \"Aggregated number of captions\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b0b9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive.run(create_count_table_query.format(\n",
    "            table_name = caption_count_table\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa8783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive.run(create_time_table_query.format(\n",
    "            table_name = caption_add_table\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ce05c",
   "metadata": {},
   "source": [
    "## Number of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bafbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_count_query = '''\n",
    "WITH captions_counts AS ( \n",
    "    SELECT\n",
    "        \"{start_date}\" AS month, \n",
    "        COUNT(DISTINCT page_id) AS num_captions,\n",
    "        COUNT(DISTINCT(CASE WHEN regexp_extract(event_comment, \"^...wbsetlabel-add:\\\\\\\\d.(\\\\\\\\w+(-\\\\\\\\w+)?)\", 1) \n",
    "                               NOT REGEXP \"^simple|en|(en-.+)$\" \n",
    "                            THEN page_id \n",
    "                        END)) AS num_captions_non_en,\n",
    "        COUNT(DISTINCT(CASE WHEN regexp_extract(event_comment, \"^...wbsetlabel-add:\\\\\\\\d.(\\\\\\\\w+(-\\\\\\\\w+)?)\", 1) \n",
    "                               REGEXP \"^simple|en|(en-.+)$\" \n",
    "                            THEN page_id \n",
    "                        END)) AS num_captions_en\n",
    "    FROM wmf.mediawiki_history\n",
    "    WHERE snapshot = \"{snapshot}\"\n",
    "    AND wiki_db = \"commonswiki\"\n",
    "    AND event_entity = \"revision\"\n",
    "    AND event_type = \"create\"\n",
    "    AND event_timestamp >= \"{start_date}\"\n",
    "    AND event_timestamp < \"{end_date}\"\n",
    "    AND page_is_deleted = false -- only count live pages\n",
    "    AND page_namespace = 6 -- only count files\n",
    "    AND event_comment REGEXP \"^...wbsetlabel-add\"\n",
    ")\n",
    "\n",
    "INSERT INTO {aggregate_table}\n",
    "SELECT \n",
    "    month,\n",
    "    num_captions,\n",
    "    num_captions_non_en,\n",
    "    num_captions_en,\n",
    "    (num_captions_non_en + num_captions_en - num_captions) AS num_captions_both\n",
    "FROM captions_counts\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3817348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/30 06:16:01 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "[Stage 1:============================>                       (3321 + 85) / 6144]22/03/30 06:16:50 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 36 for reason Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:16:50 ERROR YarnScheduler: Lost executor 36 on an-worker1105.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 1:============================================>      (5329 + 204) / 6144]22/03/30 06:18:35 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 116 for reason Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:35 ERROR YarnScheduler: Lost executor 116 on an-worker1139.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:35 WARN TaskSetManager: Lost task 6062.0 in stage 1.0 (TID 5472, an-worker1139.eqiad.wmnet, executor 116): ExecutorLostFailure (executor 116 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:35 WARN TaskSetManager: Lost task 5323.0 in stage 1.0 (TID 5352, an-worker1139.eqiad.wmnet, executor 116): ExecutorLostFailure (executor 116 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:35 WARN TaskSetManager: Lost task 5478.0 in stage 1.0 (TID 5363, an-worker1139.eqiad.wmnet, executor 116): ExecutorLostFailure (executor 116 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:35 WARN TaskSetManager: Lost task 4198.0 in stage 1.0 (TID 5133, an-worker1139.eqiad.wmnet, executor 116): ExecutorLostFailure (executor 116 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 1:============================================>      (5354 + 189) / 6144]22/03/30 06:18:35 WARN TransportChannelHandler: Exception in connection from /10.64.5.14:38356\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 1:===================================================> (5916 + 8) / 6144]22/03/30 06:18:56 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 129 for reason Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:56 ERROR YarnScheduler: Lost executor 129 on an-worker1112.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:56 WARN TaskSetManager: Lost task 4056.0 in stage 1.0 (TID 5920, an-worker1112.eqiad.wmnet, executor 129): ExecutorLostFailure (executor 129 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:56 WARN TaskSetManager: Lost task 4085.0 in stage 1.0 (TID 5923, an-worker1112.eqiad.wmnet, executor 129): ExecutorLostFailure (executor 129 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:56 WARN TaskSetManager: Lost task 4093.0 in stage 1.0 (TID 5925, an-worker1112.eqiad.wmnet, executor 129): ExecutorLostFailure (executor 129 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:18:56 WARN TaskSetManager: Lost task 2751.0 in stage 1.0 (TID 5766, an-worker1112.eqiad.wmnet, executor 129): ExecutorLostFailure (executor 129 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 1:===================================================> (5917 + 4) / 6144]22/03/30 06:18:56 WARN TransportChannelHandler: Exception in connection from /10.64.53.42:44710\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(caption_count_query.format(\n",
    "    snapshot = wmf_snapshot,\n",
    "    start_date = start_date,\n",
    "    end_date = end_date,\n",
    "    aggregate_table = caption_count_table\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1aeaf",
   "metadata": {},
   "source": [
    "## Time to add captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6bf639",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_add_query = '''\n",
    "WITH captions_time AS (\n",
    "    SELECT \n",
    "        CASE WHEN regexp_extract(event_comment, \"^...wbsetlabel-add:\\\\\\\\d.(\\\\\\\\w+(-\\\\\\\\w+)?)\", 1)\n",
    "                 NOT REGEXP \"^simple|en|(en-.+)$\" THEN \"non-en\"\n",
    "             WHEN regexp_extract(event_comment, \"^...wbsetlabel-add:\\\\\\\\d.(\\\\\\\\w+(-\\\\\\\\w+)?)\", 1)\n",
    "                 REGEXP \"^simple|en|(en-.+)$\" THEN \"en\"\n",
    "        END AS caption_language,\n",
    "        unix_timestamp(event_timestamp) - unix_timestamp(page_creation_timestamp) AS time_to_caption\n",
    "    FROM wmf.mediawiki_history\n",
    "    WHERE snapshot = \"{snapshot}\"\n",
    "    AND wiki_db = \"commonswiki\"\n",
    "    AND event_entity = \"revision\"\n",
    "    AND event_type = \"create\"\n",
    "    AND event_timestamp >= \"{start_date}\"\n",
    "    AND event_timestamp < \"{end_date}\"\n",
    "    AND page_is_deleted = false -- only count live pages\n",
    "    AND page_namespace = 6 -- only count files\n",
    "    AND event_comment REGEXP \"^...wbsetlabel-add\"\n",
    "),\n",
    "\n",
    "bucketed_captions_time AS (\n",
    "    SELECT \n",
    "        caption_language,\n",
    "        CASE WHEN time_to_caption < 60 THEN '0-1min'\n",
    "             WHEN time_to_caption >= 60 and time_to_caption < 5*60 THEN '1-5min'\n",
    "             WHEN time_to_caption >= 5*60 and time_to_caption < 60*60 THEN '5-60min'\n",
    "             WHEN time_to_caption >= 60*60 and time_to_caption < 60*60*12 THEN '1-12h'\n",
    "             WHEN time_to_caption >= 60*60*12 and time_to_caption < 60*60*24 THEN '12-24h'\n",
    "             WHEN time_to_caption >= 60*60*24 and time_to_caption < 7*24*60*60 THEN '1d-1w'\n",
    "             WHEN time_to_caption >= 60*60*24*7 and time_to_caption < 30*24*60*60 THEN '1w-1m'\n",
    "             WHEN time_to_caption >= 30*24*60*60 and time_to_caption < 180*24*60*60 THEN '1m-6m'\n",
    "             WHEN time_to_caption >= 60*60*24*180 and time_to_caption < 365*24*60*60 THEN '6m-1y'\n",
    "             WHEN time_to_caption >= 60*60*24*365 and time_to_caption < 365*24*60*60*5 THEN '1y-5y'\n",
    "             WHEN time_to_caption >= 365*24*60*60*5 THEN '5y+'\n",
    "        END AS caption_time,\n",
    "        time_to_caption\n",
    "    FROM captions_time\n",
    ")\n",
    "\n",
    "INSERT INTO {aggregate_table}\n",
    "SELECT\n",
    "    \"{start_date}\" AS month, \n",
    "    caption_language,\n",
    "    caption_time,\n",
    "    MAX(time_to_caption) AS max_caption_time, \n",
    "    COUNT(*) AS num_captions\n",
    "FROM bucketed_captions_time\n",
    "GROUP BY caption_language,caption_time\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2343635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==========>                                        (1208 + 493) / 6144]22/03/30 06:19:33 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 39 for reason Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:33 ERROR YarnScheduler: Lost executor 39 on an-worker1105.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:33 WARN TaskSetManager: Lost task 920.0 in stage 5.0 (TID 7299, an-worker1105.eqiad.wmnet, executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:33 WARN TaskSetManager: Lost task 1363.0 in stage 5.0 (TID 7774, an-worker1105.eqiad.wmnet, executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:33 WARN TaskSetManager: Lost task 1013.0 in stage 5.0 (TID 7460, an-worker1105.eqiad.wmnet, executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:33 WARN TaskSetManager: Lost task 1840.0 in stage 5.0 (TID 8119, an-worker1105.eqiad.wmnet, executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:===============>                                   (1872 + 408) / 6144]22/03/30 06:19:36 ERROR YarnScheduler: Lost executor 2 on an-worker1103.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 3348.0 in stage 5.0 (TID 8795, an-worker1103.eqiad.wmnet, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 3078.0 in stage 5.0 (TID 8750, an-worker1103.eqiad.wmnet, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 3097.0 in stage 5.0 (TID 8777, an-worker1103.eqiad.wmnet, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 3187.0 in stage 5.0 (TID 8788, an-worker1103.eqiad.wmnet, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:================>                                  (1999 + 392) / 6144]22/03/30 06:19:36 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 38 for reason Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 ERROR YarnScheduler: Lost executor 38 on an-worker1105.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 2430.0 in stage 5.0 (TID 8797, an-worker1105.eqiad.wmnet, executor 38): ExecutorLostFailure (executor 38 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 1178.0 in stage 5.0 (TID 7571, an-worker1105.eqiad.wmnet, executor 38): ExecutorLostFailure (executor 38 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 1822.0 in stage 5.0 (TID 8088, an-worker1105.eqiad.wmnet, executor 38): ExecutorLostFailure (executor 38 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:36 WARN TaskSetManager: Lost task 1967.0 in stage 5.0 (TID 8254, an-worker1105.eqiad.wmnet, executor 38): ExecutorLostFailure (executor 38 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:=================>                                 (2168 + 352) / 6144]22/03/30 06:19:37 WARN TransportChannelHandler: Exception in connection from /10.64.36.137:51910\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 5:==================>                                (2207 + 335) / 6144]22/03/30 06:19:37 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container killed by YARN for exceeding memory limits.  9.4 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:37 ERROR YarnScheduler: Lost executor 4 on an-worker1113.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.4 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:37 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container killed by YARN for exceeding memory limits.  9.5 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:37 ERROR YarnScheduler: Lost executor 3 on an-worker1113.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.5 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:37 WARN TaskSetManager: Lost task 6063.0 in stage 5.0 (TID 8803, an-worker1113.eqiad.wmnet, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.5 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:==================>                                (2241 + 328) / 6144]22/03/30 06:19:38 WARN TransportChannelHandler: Exception in connection from /10.64.53.43:43340\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 5:=====================>                             (2534 + 256) / 6144]22/03/30 06:19:40 ERROR YarnScheduler: Lost executor 1 on an-worker1136.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 27 for reason Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 37 for reason Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 ERROR YarnScheduler: Lost executor 27 on an-worker1109.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 5994.0 in stage 5.0 (TID 9404, an-worker1109.eqiad.wmnet, executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 5002.0 in stage 5.0 (TID 9134, an-worker1109.eqiad.wmnet, executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 5663.0 in stage 5.0 (TID 9322, an-worker1109.eqiad.wmnet, executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 5529.0 in stage 5.0 (TID 9268, an-worker1109.eqiad.wmnet, executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 ERROR YarnScheduler: Lost executor 37 on an-worker1105.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 3242.0 in stage 5.0 (TID 9401, an-worker1105.eqiad.wmnet, executor 37): ExecutorLostFailure (executor 37 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 3125.0 in stage 5.0 (TID 9380, an-worker1105.eqiad.wmnet, executor 37): ExecutorLostFailure (executor 37 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 2906.0 in stage 5.0 (TID 9221, an-worker1105.eqiad.wmnet, executor 37): ExecutorLostFailure (executor 37 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 3026.0 in stage 5.0 (TID 9235, an-worker1105.eqiad.wmnet, executor 37): ExecutorLostFailure (executor 37 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:=====================>                             (2550 + 245) / 6144]22/03/30 06:19:40 WARN TransportChannelHandler: Exception in connection from /10.64.36.141:44128\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 5:=====================>                             (2588 + 236) / 6144]22/03/30 06:19:40 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 88 for reason Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 ERROR YarnScheduler: Lost executor 88 on an-worker1140.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 2664.0 in stage 5.0 (TID 9464, an-worker1140.eqiad.wmnet, executor 88): ExecutorLostFailure (executor 88 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 2749.0 in stage 5.0 (TID 9513, an-worker1140.eqiad.wmnet, executor 88): ExecutorLostFailure (executor 88 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 2725.0 in stage 5.0 (TID 9507, an-worker1140.eqiad.wmnet, executor 88): ExecutorLostFailure (executor 88 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:40 WARN TaskSetManager: Lost task 2673.0 in stage 5.0 (TID 9465, an-worker1140.eqiad.wmnet, executor 88): ExecutorLostFailure (executor 88 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:=====================>                             (2611 + 229) / 6144]22/03/30 06:19:40 WARN TransportChannelHandler: Exception in connection from /10.64.36.137:51896\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 5:===========================>                        (3255 + 94) / 6144]22/03/30 06:19:49 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 46 for reason Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:49 ERROR YarnScheduler: Lost executor 46 on an-worker1131.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.1 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:============================>                       (3328 + 82) / 6144]22/03/30 06:19:50 ERROR YarnScheduler: Lost executor 62 on analytics1071.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.5 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:19:50 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 62 for reason Container killed by YARN for exceeding memory limits.  9.5 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:===============================>                    (3689 + 23) / 6144]22/03/30 06:20:05 ERROR YarnScheduler: Lost executor 137 on an-worker1135.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:05 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 137 for reason Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:05 WARN TaskSetManager: Lost task 6071.0 in stage 5.0 (TID 10379, an-worker1135.eqiad.wmnet, executor 137): ExecutorLostFailure (executor 137 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:05 WARN TaskSetManager: Lost task 6082.0 in stage 5.0 (TID 10381, an-worker1135.eqiad.wmnet, executor 137): ExecutorLostFailure (executor 137 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:05 WARN TaskSetManager: Lost task 5951.0 in stage 5.0 (TID 10375, an-worker1135.eqiad.wmnet, executor 137): ExecutorLostFailure (executor 137 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:======================================>            (4664 + 353) / 6144]22/03/30 06:20:47 ERROR YarnScheduler: Lost executor 21 on an-worker1105.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:47 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 21 for reason Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:47 WARN TaskSetManager: Lost task 1199.0 in stage 5.0 (TID 11310, an-worker1105.eqiad.wmnet, executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:47 WARN TaskSetManager: Lost task 1386.0 in stage 5.0 (TID 11354, an-worker1105.eqiad.wmnet, executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:47 WARN TaskSetManager: Lost task 1286.0 in stage 5.0 (TID 11324, an-worker1105.eqiad.wmnet, executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:47 WARN TaskSetManager: Lost task 1854.0 in stage 5.0 (TID 11574, an-worker1105.eqiad.wmnet, executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:=========================================>         (5008 + 226) / 6144]22/03/30 06:20:49 ERROR YarnScheduler: Lost executor 19 on an-worker1087.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:49 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 19 for reason Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:49 WARN TaskSetManager: Lost task 3928.0 in stage 5.0 (TID 11788, an-worker1087.eqiad.wmnet, executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:49 WARN TaskSetManager: Lost task 4445.0 in stage 5.0 (TID 11838, an-worker1087.eqiad.wmnet, executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:49 WARN TaskSetManager: Lost task 3600.0 in stage 5.0 (TID 11757, an-worker1087.eqiad.wmnet, executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:49 WARN TaskSetManager: Lost task 3535.0 in stage 5.0 (TID 11748, an-worker1087.eqiad.wmnet, executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  9.0 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:============================================>      (5330 + 155) / 6144]22/03/30 06:20:52 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 112 for reason Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:52 ERROR YarnScheduler: Lost executor 112 on an-worker1139.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:52 WARN TaskSetManager: Lost task 3754.0 in stage 5.0 (TID 11974, an-worker1139.eqiad.wmnet, executor 112): ExecutorLostFailure (executor 112 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:52 WARN TaskSetManager: Lost task 3990.0 in stage 5.0 (TID 12033, an-worker1139.eqiad.wmnet, executor 112): ExecutorLostFailure (executor 112 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:52 WARN TaskSetManager: Lost task 3998.0 in stage 5.0 (TID 12038, an-worker1139.eqiad.wmnet, executor 112): ExecutorLostFailure (executor 112 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:20:52 WARN TaskSetManager: Lost task 4124.0 in stage 5.0 (TID 12086, an-worker1139.eqiad.wmnet, executor 112): ExecutorLostFailure (executor 112 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.9 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:================================================>   (5786 + 41) / 6144]22/03/30 06:21:04 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 142 for reason Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:21:04 ERROR YarnScheduler: Lost executor 142 on an-worker1102.eqiad.wmnet: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:21:04 WARN TaskSetManager: Lost task 5653.0 in stage 5.0 (TID 12524, an-worker1102.eqiad.wmnet, executor 142): ExecutorLostFailure (executor 142 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:21:04 WARN TaskSetManager: Lost task 5723.0 in stage 5.0 (TID 12529, an-worker1102.eqiad.wmnet, executor 142): ExecutorLostFailure (executor 142 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:21:04 WARN TaskSetManager: Lost task 5690.0 in stage 5.0 (TID 12525, an-worker1102.eqiad.wmnet, executor 142): ExecutorLostFailure (executor 142 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "22/03/30 06:21:04 WARN TaskSetManager: Lost task 5624.0 in stage 5.0 (TID 12519, an-worker1102.eqiad.wmnet, executor 142): ExecutorLostFailure (executor 142 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  8.8 GB of 8.8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.\n",
      "[Stage 5:=================================================>  (5809 + 36) / 6144]22/03/30 06:21:05 WARN TransportChannelHandler: Exception in connection from /10.64.5.40:56004\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(caption_add_query.format(\n",
    "    snapshot = wmf_snapshot,\n",
    "    start_date = start_date,\n",
    "    end_date = end_date,\n",
    "    aggregate_table = caption_add_table\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
